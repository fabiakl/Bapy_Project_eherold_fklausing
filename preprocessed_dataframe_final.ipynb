{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed Dataframe\n",
    "\n",
    "## Input:\n",
    "In this Notebook we are working with the two dataframes \"credits_cleaned.csv\" and \"movie_metadata.csv\", we've previously created from the original datasets.\n",
    "We already deleted all the movies, that don't occur in all of our datasets (meaning the script files as well as the two data frames with meta data about the movvies).\n",
    "\n",
    "## Output:\n",
    "Now, we want to sum up our \"credits_cleaned\" and \"movie_metadata\" cleaned in a way, that we get a single Dataframe with only the coulmns that are relevant for us. \n",
    "For that, we create a new Dataframe take over the relevant columns from the respective Dataframe. \n",
    "Note, that in case of the genre column we split it up into three separate columns for each genre, instead of having one column with a dictionary for all genres,\n",
    "as wee need to individually call the genres later on. \n",
    "At the end, we get a single Dataframe with the following columns: character,\tactress/actor,\tgender,\ttitle_of_movie,\tgenre1,\tgenre2,\tgenre3, release date, budget, voting, original language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd \n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading both our cleaned datasets\n",
    "df = pd.read_csv('credits_cleaned.csv')\n",
    "df_2 = pd.read_csv('movies_metadata_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the new Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a data_frame that only has the useful information \n",
    "clean_data = {'character': [], \"actress/actor\": [], \"gender\": [], \"title_of_movie\": [], \"genre1\": [], \"genre2\": [], \"genre3\": [], \"release_date\": [], \"budget\": [], \"voting\": [], \"original_language\": []} \n",
    "# this creates an empty dataframe, only the column names are defined\n",
    "clean_frame = pd.DataFrame(clean_data)\n",
    "\n",
    "#lets get the useful columns from our data-sets\n",
    "cast_col = df['cast']\n",
    "#Here we turn the strings in the cast_col into lists of dictionaries, so we can work with them\n",
    "cast_col = [eval(single_movie) for single_movie in cast_col]\n",
    "# getting the titles for our dataFrame\n",
    "title_col = df_2['original_title']\n",
    "# getting the genres of movies\n",
    "genres_col = df_2['genres']\n",
    "#Here we turn the strings in the genre_col into lists of dictionaries, so we can work with them\n",
    "genres_col = [eval(single_movie) for single_movie in genres_col]\n",
    "# Extracting the genres is a bit more complicated, because we need to extract all genres from the dict in the one genre column\n",
    "# Because there is also other information given in the dictionaries, we create a list with only the genres \n",
    "# (3 genres for each movie)\n",
    "liste = 0\n",
    "genre_list = []\n",
    "# We want to look into every movie of the genre col\n",
    "while liste < len(genres_col):\n",
    "    count = 0\n",
    "    # counting the nr. of genres, because for some movies there are more, but we are only interested in 3\n",
    "    while count < 3:\n",
    "        # We try to append the genre to our genre list\n",
    "        try:\n",
    "            genre_list.append(genres_col[liste][count].get('name'))\n",
    "            count += 1\n",
    "        # If there is no genre given, we append an empty string\n",
    "        except:                              \n",
    "            genre_list.append(\"\")\n",
    "            count += 1 \n",
    "    liste += 1\n",
    "# getting the release dates of the movies\n",
    "release_col = df_2['release_date']\n",
    "# getting the budget of the movies\n",
    "budget_col = df_2['budget']\n",
    "# getting the voting of the movies\n",
    "voting_col= df_2['vote_average']\n",
    "# getting the original language of the movies\n",
    "language_col = df_2['original_language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_counter = -1 # for proper index\n",
    "# we will need this for genre list later\n",
    "count = 0 \n",
    "# in the first for loop we operate on the level of the different movies, stored in our column\n",
    "for index, movie in enumerate(title_col): \n",
    "    # Here we look into the single cast members of the respective movie\n",
    "    for i, m in enumerate(cast_col[index]): # we can do so by accessing the cast_col via the index from our first for loop\n",
    "        # Now we add a row for every cast member in each movie\n",
    "        index_counter += 1\n",
    "        # here we add a row to our dataframe with the previously specified content\n",
    "        # Note how we use the \"count\" variable to get the proper index for our \"genre_list\"\n",
    "        clean_frame.loc[index_counter] = m['character'], m['name'], m['gender'], title_col[index], genre_list[count], genre_list[count+1], genre_list[count+2], release_col[index], budget_col[index], voting_col[index], language_col[index]\n",
    "    count += 3 # we raise this count by 3 because in our genre list we have 3 genres given for each movie\n",
    "\n",
    "# At the end, we reset our index\n",
    "clean_frame = clean_frame.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting missing Genders \n",
    "Our Dataset is incomplete in respect to the specified genders of the actresses/actors. \n",
    "For all missing values, they marked the gender as \"0.0\". \n",
    "In the following code snippets,\n",
    "we tried to minimize the missing gender values by accessing the actressses'/actors' Wikipedia entries and extracting their genders from there.\n",
    "Note, that we still have missing values aferwards because some more unknown people in our dataset dont have a Wikipedia entry,\n",
    "but we didn't see an easily realizable way to fill up those missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(name):\n",
    "    \"\"\"\n",
    "    Assigns a Gender to a Person according to their Wikipedia-entry.\n",
    "  \n",
    "    Parameters:\n",
    "    name (str): the name of the actor/actress whose Gender is currently missing\n",
    "  \n",
    "    Returns:\n",
    "    int: either 1.0 (for female) or 2.0 (for male)\n",
    "  \n",
    "    \"\"\"\n",
    "    # processing of the name so it fits into the URL\n",
    "    name = name.replace(\" \", \"_\")\n",
    "    # getting all html tables of the respective Wiki page\n",
    "    scraper = pd.read_html(\"https://de.wikipedia.org/wiki/{}\".format(name))\n",
    "        \n",
    "    index = 0\n",
    "    # In case there are multiple HTML tables in the wiki-entry, \n",
    "    # we are filtering for the one called \"Personendaten\"\n",
    "    for idx, table in enumerate(scraper):\n",
    "        if table.columns[0] == \"Personendaten\":\n",
    "            index = idx\n",
    "            break\n",
    "                \n",
    "    # changing the index column so we can access the entry via \"KURZBESCHREIBUNG\"\n",
    "    new_index = scraper[index].set_index('Personendaten')\n",
    "    # Accessing the entry where it is either stated \"Schauspieler\" or \"Schauspielerin\"\n",
    "    # We decide about the gender of the person via the gendered german gob description of \"Schauspieler\" vs. \"Schauspielerin\"\n",
    "    personen_daten = new_index.at['KURZBESCHREIBUNG', 'Personendaten.1']\n",
    "    # Regular expression that can match any string that includes the german word for \"actress\" in any form\n",
    "    g = re.compile(r\".*(S|s)(chauspielerin).*\".format(personen_daten), re.DOTALL)\n",
    "\n",
    "    # Whether or not the \"personen_daten\"-entry matches with our regular expression, decides about the assigned gender of our person\n",
    "    if g.match(personen_daten):\n",
    "        # 1.0 == female in our DataFrame\n",
    "        assigned_gender = 1.0\n",
    "    else:\n",
    "        # 2.0 == male in our DataFrame\n",
    "        assigned_gender = 2.0\n",
    "        \n",
    "    return assigned_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply our function onto every entry in our gender column\n",
    "for i, line in enumerate(clean_frame['gender']):\n",
    "    # In case there is a row with no assigned gender\n",
    "    if line == 0.0:\n",
    "        # We try to get the gender through their Wikipedia entry\n",
    "        try: \n",
    "            name = clean_frame.at[i, 'actress/actor']\n",
    "            gender = get_gender(name)\n",
    "        # If this is not possible (maybe the person doesnt have a wiki-entry), we leave it unassigned\n",
    "        except:\n",
    "            gender = 0.0\n",
    "        clean_frame.at[i, 'gender'] = gender\n",
    "\n",
    "# # Saving the dataframe into a CSV for later use, so we don't have to run the code of this notebook every time        \n",
    "clean_frame.to_csv(\"movie_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataframe \n",
    "Now we have created the Dataframe, which we later on use for conducting the actual Bechdel-test!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c0ed15480eb423fdcd544667b7c2fa037f1a5a812dbe50b2b749b93b43ae443"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
